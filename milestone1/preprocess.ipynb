{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "def process_emotion_dataset(input_dir: str, output_dir: str, team_id: str = \"08\", image_size: tuple = (640, 480)):\n",
    "    \"\"\"\n",
    "    Processes a dataset of facial emotion images and outputs it in the format required by Milestone 1.\n",
    "\n",
    "    Args:\n",
    "        input_dir (str): Path to input directory containing class folders.\n",
    "        output_dir (str): Path to save processed images.\n",
    "        team_id (str): 2-digit team identifier, e.g., '01', '12'.\n",
    "        image_size (tuple): Output image size (width, height), default is (640, 480).\n",
    "    \"\"\"\n",
    "    # Ensure team ID is valid\n",
    "    assert len(team_id) == 2 and team_id.isdigit(), \"Team ID must be a 2-digit number string.\"\n",
    "\n",
    "    input_dir = Path(input_dir)\n",
    "    output_dir = Path(output_dir)\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    for class_folder in input_dir.iterdir():\n",
    "        if not class_folder.is_dir():\n",
    "            continue\n",
    "\n",
    "        class_name = class_folder.name.upper()\n",
    "        class_output_dir = output_dir / class_name\n",
    "        class_output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        print(f\"Processing class: {class_name}\")\n",
    "        image_count = 0\n",
    "\n",
    "        for file in tqdm(sorted(class_folder.iterdir())):\n",
    "            if not file.is_file():\n",
    "                continue\n",
    "\n",
    "            # Read image\n",
    "            img = cv2.imread(str(file))\n",
    "            if img is None:\n",
    "                print(f\"‚ö†Ô∏è Skipping unreadable image: {file}\")\n",
    "                continue\n",
    "\n",
    "            # Resize\n",
    "            img_resized = cv2.resize(img, image_size)\n",
    "\n",
    "            # Filename: C_T_N.png (C=CLASS, T=team_id, N=4-digit number)\n",
    "            serial_number = f\"{image_count:04d}\"\n",
    "            output_filename = f\"{class_name[0]}_{team_id}_{serial_number}.png\"\n",
    "            output_path = class_output_dir / output_filename\n",
    "\n",
    "            # Save image\n",
    "            cv2.imwrite(str(output_path), img_resized)\n",
    "            image_count += 1\n",
    "\n",
    "        print(f\"[{class_name}] ‚úÖ Processed {image_count} images.\")\n",
    "\n",
    "    print(\"üéâ Dataset preprocessing complete according to Milestone 1 format.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing class: ANGRY\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50a34b97536c4ce4abc2da984f4a41f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/115 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ANGRY] ‚úÖ Processed 115 images.\n",
      "Processing class: HAPPY\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6ab6334f05a4e37904546402f8c8ad3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/114 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HAPPY] ‚úÖ Processed 114 images.\n",
      "Processing class: NEUTRAL\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a95ae98fc984bc99f92e917d5b73154",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/112 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NEUTRAL] ‚úÖ Processed 112 images.\n",
      "Processing class: SAD\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "525a66ea99c84fb7b14d5ce3899ae800",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SAD] ‚úÖ Processed 45 images.\n",
      "üéâ Dataset preprocessing complete according to Milestone 1 format.\n"
     ]
    }
   ],
   "source": [
    "process_emotion_dataset(\n",
    "    input_dir=\"./Project\",\n",
    "    output_dir=\"./final_dataset\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-gpu",
   "language": "python",
   "name": "pytorch-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
