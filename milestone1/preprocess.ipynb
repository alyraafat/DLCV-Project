{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "import random\n",
    "\n",
    "def process_emotion_dataset(input_dir: str, output_dir: str, team_id: str = \"08\", image_size: tuple = (640, 480)):\n",
    "    \"\"\"\n",
    "    Processes a dataset of facial emotion images and outputs it in the format required by Milestone 1.\n",
    "\n",
    "    Args:\n",
    "        input_dir (str): Path to input directory containing class folders.\n",
    "        output_dir (str): Path to save processed images.\n",
    "        team_id (str): 2-digit team identifier, e.g., '01', '12'.\n",
    "        image_size (tuple): Output image size (width, height), default is (640, 480).\n",
    "    \"\"\"\n",
    "    # Ensure team ID is valid\n",
    "    assert len(team_id) == 2 and team_id.isdigit(), \"Team ID must be a 2-digit number string.\"\n",
    "\n",
    "    input_dir = Path(input_dir)\n",
    "    output_dir = Path(output_dir)\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    for class_folder in input_dir.iterdir():\n",
    "        if not class_folder.is_dir():\n",
    "            continue\n",
    "\n",
    "        class_name = class_folder.name.upper()\n",
    "        class_output_dir = output_dir / class_name\n",
    "        class_output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        print(f\"Processing class: {class_name}\")\n",
    "        image_count = 0\n",
    "\n",
    "        # Get and shuffle image files\n",
    "        image_files = list(class_folder.glob(\"*\"))\n",
    "        image_files = [f for f in image_files if f.is_file()]\n",
    "        # random.shuffle(image_files)\n",
    "\n",
    "\n",
    "        for file in tqdm(image_files):\n",
    "            if not file.is_file():\n",
    "                continue\n",
    "\n",
    "            # Read image\n",
    "            img = cv2.imread(str(file))\n",
    "            if img is None:\n",
    "                print(f\"‚ö†Ô∏è Skipping unreadable image: {file}\")\n",
    "                continue\n",
    "\n",
    "            # Resize\n",
    "            img_resized = cv2.resize(img, image_size)\n",
    "\n",
    "            # Filename: C_T_N.png (C=CLASS, T=team_id, N=4-digit number)\n",
    "            serial_number = f\"{image_count:04d}\"\n",
    "            output_filename = f\"{class_name[0]}_{team_id}_{serial_number}.png\"\n",
    "            output_path = class_output_dir / output_filename\n",
    "\n",
    "            # Save image\n",
    "            cv2.imwrite(str(output_path), img_resized)\n",
    "            image_count += 1\n",
    "\n",
    "        print(f\"[{class_name}] ‚úÖ Processed {image_count} images.\")\n",
    "\n",
    "    print(\"üéâ Dataset preprocessing complete according to Milestone 1 format.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing class: ANGRY\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51c0780dfed6437bb9456dd2eb537987",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ANGRY] ‚úÖ Processed 125 images.\n",
      "Processing class: HAPPY\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "031a8823dadc4831a830bad6df6d7769",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/114 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HAPPY] ‚úÖ Processed 114 images.\n",
      "Processing class: NEUTRAL\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96e816a046434b2582f7e251da041716",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/112 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NEUTRAL] ‚úÖ Processed 112 images.\n",
      "Processing class: SAD\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e54f72edf67a40de8b44eae81b42b951",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SAD] ‚úÖ Processed 119 images.\n",
      "üéâ Dataset preprocessing complete according to Milestone 1 format.\n"
     ]
    }
   ],
   "source": [
    "process_emotion_dataset(\n",
    "    input_dir=\"./Project\",\n",
    "    output_dir=\"./final_dataset_2\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = cv2.imread(\"./Project/Sad/Screenshot from 2025-04-02 21-31-59.png\")\n",
    "\n",
    "img_resized = cv2.resize(img, (640, 480))\n",
    "cv2.imwrite(\"./final_dataset/SAD/S_08_0007.png\", img_resized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "import random\n",
    "\n",
    "def shuffle_and_rename_emotion_dataset(input_dir: str, output_dir: str, team_id: str = \"08\"):\n",
    "    \"\"\"\n",
    "    shuffle and rename  a dataset of facial emotion images and outputs it in the format required by Milestone 1.\n",
    "\n",
    "    Args:\n",
    "        input_dir (str): Path to input directory containing class folders.\n",
    "        output_dir (str): Path to save processed images.\n",
    "        team_id (str): 2-digit team identifier, e.g., '01', '12'.\n",
    "    \"\"\"\n",
    "    # Ensure team ID is valid\n",
    "    assert len(team_id) == 2 and team_id.isdigit(), \"Team ID must be a 2-digit number string.\"\n",
    "\n",
    "    input_dir = Path(input_dir)\n",
    "    output_dir = Path(output_dir)\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    for class_folder in input_dir.iterdir():\n",
    "        if not class_folder.is_dir():\n",
    "            continue\n",
    "\n",
    "        class_name = class_folder.name.upper()\n",
    "        class_output_dir = output_dir / class_name\n",
    "        class_output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        print(f\"Processing class: {class_name}\")\n",
    "        image_count = 0\n",
    "\n",
    "        # Get and shuffle image files\n",
    "        image_files = list(class_folder.glob(\"*\"))\n",
    "        image_files = [f for f in image_files if f.is_file()]\n",
    "        random.shuffle(image_files)\n",
    "\n",
    "\n",
    "        for file in tqdm(image_files):\n",
    "            if not file.is_file():\n",
    "                continue\n",
    "\n",
    "            # Read image\n",
    "            img = cv2.imread(str(file))\n",
    "            if img is None:\n",
    "                print(f\"‚ö†Ô∏è Skipping unreadable image: {file}\")\n",
    "                continue\n",
    "\n",
    "            # Filename: C_T_N.png (C=CLASS, T=team_id, N=4-digit number)\n",
    "            serial_number = f\"{image_count:04d}\"\n",
    "            output_filename = f\"{class_name[0]}_{team_id}_{serial_number}.png\"\n",
    "            output_path = class_output_dir / output_filename\n",
    "\n",
    "            # Save image\n",
    "            cv2.imwrite(str(output_path), img)\n",
    "            image_count += 1\n",
    "\n",
    "        print(f\"[{class_name}] ‚úÖ Processed {image_count} images.\")\n",
    "\n",
    "    print(\"üéâ Dataset preprocessing complete according to Milestone 1 format.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing class: ANGRY\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4379911cc8b4f18b815dfad3479c2cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ANGRY] ‚úÖ Processed 116 images.\n",
      "Processing class: HAPPY\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0054d7f1c5b4a3696c3503f91886772",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/112 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HAPPY] ‚úÖ Processed 112 images.\n",
      "Processing class: NEUTRAL\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0c306a703c446c2805268523ce87d9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/112 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NEUTRAL] ‚úÖ Processed 112 images.\n",
      "Processing class: SAD\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d84031a9d1442b5bdcd5ee9f3b2ec58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/115 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SAD] ‚úÖ Processed 115 images.\n",
      "üéâ Dataset preprocessing complete according to Milestone 1 format.\n"
     ]
    }
   ],
   "source": [
    "shuffle_and_rename_emotion_dataset(\n",
    "    input_dir=\"./final_dataset_2\",\n",
    "    output_dir=\"./final_dataset_submission\",\n",
    "    team_id=\"08\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-gpu",
   "language": "python",
   "name": "pytorch-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
